{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a48960d6",
   "metadata": {},
   "source": [
    "# Part 1: Compare the different compiler setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7acaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb \n",
    "(train_data, train_labels),(test_data, test_labels) = imdb.load_data( num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d67c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db28c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996a14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a15ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7c6da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data) \n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dcf6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140dc134",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd28e545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e8ac994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    }
   ],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf0bf4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25785981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 2s 38ms/step - loss: 0.4945 - acc: 0.7919 - val_loss: 0.3609 - val_acc: 0.8794\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2879 - acc: 0.9059 - val_loss: 0.2982 - val_acc: 0.8849\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2150 - acc: 0.9283 - val_loss: 0.2777 - val_acc: 0.8903\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.1705 - acc: 0.9451 - val_loss: 0.2763 - val_acc: 0.8902\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.1377 - acc: 0.9561 - val_loss: 0.2815 - val_acc: 0.8896\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.1155 - acc: 0.9639 - val_loss: 0.2963 - val_acc: 0.8849\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0945 - acc: 0.9732 - val_loss: 0.3271 - val_acc: 0.8812\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0794 - acc: 0.9773 - val_loss: 0.3987 - val_acc: 0.8679\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0669 - acc: 0.9815 - val_loss: 0.3613 - val_acc: 0.8769\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0536 - acc: 0.9869 - val_loss: 0.3878 - val_acc: 0.8774\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0427 - acc: 0.9902 - val_loss: 0.4179 - val_acc: 0.8718\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0358 - acc: 0.9921 - val_loss: 0.4717 - val_acc: 0.8652\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0298 - acc: 0.9941 - val_loss: 0.4725 - val_acc: 0.8718\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0234 - acc: 0.9959 - val_loss: 0.5052 - val_acc: 0.8712\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.0211 - acc: 0.9955 - val_loss: 0.5330 - val_acc: 0.8703\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0116 - acc: 0.9991 - val_loss: 0.5667 - val_acc: 0.8676\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0121 - acc: 0.9985 - val_loss: 0.6066 - val_acc: 0.8680\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0117 - acc: 0.9979 - val_loss: 0.6374 - val_acc: 0.8670\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0051 - acc: 0.9997 - val_loss: 0.6707 - val_acc: 0.8660\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0054 - acc: 0.9996 - val_loss: 0.7136 - val_acc: 0.8638\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c06ec3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee575150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "acc_values = history_dict['acc']\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "683dd35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/49 [==============================] - 3s 58ms/step - loss: 0.4424 - accuracy: 0.8318 - val_loss: 0.3444 - val_accuracy: 0.8826\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.2729 - accuracy: 0.9090 - val_loss: 0.3001 - val_accuracy: 0.8843\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.2186 - accuracy: 0.9253 - val_loss: 0.2887 - val_accuracy: 0.8836\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.1864 - accuracy: 0.9369 - val_loss: 0.2802 - val_accuracy: 0.8888\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1644 - accuracy: 0.9446 - val_loss: 0.2861 - val_accuracy: 0.8858\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1472 - accuracy: 0.9508 - val_loss: 0.2972 - val_accuracy: 0.8832\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1345 - accuracy: 0.9558 - val_loss: 0.3070 - val_accuracy: 0.8805\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1227 - accuracy: 0.9600 - val_loss: 0.3191 - val_accuracy: 0.8778\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1128 - accuracy: 0.9640 - val_loss: 0.3382 - val_accuracy: 0.8740\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1044 - accuracy: 0.9675 - val_loss: 0.3515 - val_accuracy: 0.8721\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.4645 - accuracy: 0.8178 - val_loss: 0.3577 - val_accuracy: 0.8635\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.2609 - accuracy: 0.9072 - val_loss: 0.2968 - val_accuracy: 0.8822\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.2021 - accuracy: 0.9260 - val_loss: 0.2829 - val_accuracy: 0.8874\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.1668 - accuracy: 0.9394 - val_loss: 0.2970 - val_accuracy: 0.8848\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.1431 - accuracy: 0.9498 - val_loss: 0.3205 - val_accuracy: 0.8794\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.1268 - accuracy: 0.9561 - val_loss: 0.3730 - val_accuracy: 0.8676\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.1120 - accuracy: 0.9606 - val_loss: 0.3779 - val_accuracy: 0.8698\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.1003 - accuracy: 0.9645 - val_loss: 0.4011 - val_accuracy: 0.8684\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.0890 - accuracy: 0.9696 - val_loss: 0.4305 - val_accuracy: 0.8649\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.0788 - accuracy: 0.9735 - val_loss: 0.4602 - val_accuracy: 0.8642\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 3s 50ms/step - loss: 0.4329 - accuracy: 0.8215 - val_loss: 0.3360 - val_accuracy: 0.8665\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.2451 - accuracy: 0.9108 - val_loss: 0.2851 - val_accuracy: 0.8866\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 10ms/step - loss: 0.1911 - accuracy: 0.9301 - val_loss: 0.3018 - val_accuracy: 0.8799\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 10ms/step - loss: 0.1617 - accuracy: 0.9405 - val_loss: 0.3071 - val_accuracy: 0.8803\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1404 - accuracy: 0.9491 - val_loss: 0.3338 - val_accuracy: 0.8751\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 1s 17ms/step - loss: 0.1153 - accuracy: 0.9586 - val_loss: 0.3788 - val_accuracy: 0.8686\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 1s 18ms/step - loss: 0.1016 - accuracy: 0.9638 - val_loss: 0.4014 - val_accuracy: 0.8668\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 1s 17ms/step - loss: 0.0849 - accuracy: 0.9716 - val_loss: 0.4324 - val_accuracy: 0.8638\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 1s 18ms/step - loss: 0.0703 - accuracy: 0.9756 - val_loss: 0.4628 - val_accuracy: 0.8633\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 1s 18ms/step - loss: 0.0607 - accuracy: 0.9798 - val_loss: 0.4933 - val_accuracy: 0.8626\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 3s 59ms/step - loss: 0.4194 - accuracy: 0.8172 - val_loss: 0.3196 - val_accuracy: 0.8736\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.2395 - accuracy: 0.9092 - val_loss: 0.2899 - val_accuracy: 0.8847\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1846 - accuracy: 0.9314 - val_loss: 0.3311 - val_accuracy: 0.8725\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.1504 - accuracy: 0.9446 - val_loss: 0.3187 - val_accuracy: 0.8777\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.1165 - accuracy: 0.9568 - val_loss: 0.4220 - val_accuracy: 0.8560\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.0914 - accuracy: 0.9681 - val_loss: 0.3925 - val_accuracy: 0.8709\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.0677 - accuracy: 0.9764 - val_loss: 0.4711 - val_accuracy: 0.8593\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.0448 - accuracy: 0.9863 - val_loss: 0.4810 - val_accuracy: 0.8651\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.5728 - val_accuracy: 0.8551\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.0265 - accuracy: 0.9919 - val_loss: 0.6087 - val_accuracy: 0.8633\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 3s 50ms/step - loss: 0.1504 - accuracy: 0.8252 - val_loss: 0.1131 - val_accuracy: 0.8753\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.9102 - val_loss: 0.0930 - val_accuracy: 0.8859\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.0650 - accuracy: 0.9285 - val_loss: 0.0886 - val_accuracy: 0.8841\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0539 - accuracy: 0.9413 - val_loss: 0.0848 - val_accuracy: 0.8877\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0468 - accuracy: 0.9482 - val_loss: 0.0870 - val_accuracy: 0.8824\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9569 - val_loss: 0.0906 - val_accuracy: 0.8773\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.0371 - accuracy: 0.9608 - val_loss: 0.0889 - val_accuracy: 0.8779\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9652 - val_loss: 0.0912 - val_accuracy: 0.8756\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9688 - val_loss: 0.0933 - val_accuracy: 0.8734\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.0277 - accuracy: 0.9730 - val_loss: 0.0953 - val_accuracy: 0.8712\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.4225 - accuracy: 0.8306 - val_loss: 0.3179 - val_accuracy: 0.8767\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.2347 - accuracy: 0.9122 - val_loss: 0.2813 - val_accuracy: 0.8856\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.1773 - accuracy: 0.9341 - val_loss: 0.3098 - val_accuracy: 0.8782\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.1489 - accuracy: 0.9461 - val_loss: 0.3296 - val_accuracy: 0.8746\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.1272 - accuracy: 0.9548 - val_loss: 0.3545 - val_accuracy: 0.8714\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.1119 - accuracy: 0.9606 - val_loss: 0.3914 - val_accuracy: 0.8668\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.1011 - accuracy: 0.9652 - val_loss: 0.4581 - val_accuracy: 0.8546\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.0944 - accuracy: 0.9664 - val_loss: 0.4508 - val_accuracy: 0.8616\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.0813 - accuracy: 0.9734 - val_loss: 0.4895 - val_accuracy: 0.8569\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.0733 - accuracy: 0.9757 - val_loss: 0.5163 - val_accuracy: 0.8560\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Load the IMDb dataset\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "# Experiment 1: Number of Hidden Layers\n",
    "# One hidden layer\n",
    "model_1 = models.Sequential()\n",
    "model_1.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model_1.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_1 = model_1.fit(x_train, y_train, epochs=10, batch_size=512, validation_data=(x_test, y_test))\n",
    "\n",
    "# Three hidden layers\n",
    "model_3 = models.Sequential()\n",
    "model_3.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model_3.add(layers.Dense(16, activation='relu'))\n",
    "model_3.add(layers.Dense(16, activation='relu'))\n",
    "model_3.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_3.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_3 = model_3.fit(x_train, y_train, epochs=10, batch_size=512, validation_data=(x_test, y_test))\n",
    "\n",
    "# Experiment 2: Number of Hidden Units\n",
    "# 32 hidden units\n",
    "model_32 = models.Sequential()\n",
    "model_32.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model_32.add(layers.Dense(32, activation='relu'))\n",
    "model_32.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_32.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_32 = model_32.fit(x_train, y_train, epochs=10, batch_size=512, validation_data=(x_test, y_test))\n",
    "\n",
    "# 64 hidden units\n",
    "model_64 = models.Sequential()\n",
    "model_64.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model_64.add(layers.Dense(64, activation='relu'))\n",
    "model_64.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_64.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_64 = model_64.fit(x_train, y_train, epochs=10, batch_size=512, validation_data=(x_test, y_test))\n",
    "\n",
    "# Experiment 3: Loss Function\n",
    "# MSE loss function\n",
    "model_mse = models.Sequential()\n",
    "model_mse.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model_mse.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_mse.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "history_mse = model_mse.fit(x_train, y_train, epochs=10, batch_size=512, validation_data=(x_test, y_test))\n",
    "\n",
    "# Experiment 4: Activation Function\n",
    "# Tanh activation function\n",
    "model_tanh = models.Sequential()\n",
    "model_tanh.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model_tanh.add(layers.Dense(16, activation='tanh'))\n",
    "model_tanh.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_tanh.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_tanh = model_tanh.fit(x_train, y_train, epochs=10, batch_size=512, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7739d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd377d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3401cb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d357be8b",
   "metadata": {},
   "source": [
    "# Part 2:  Examine the impact of regularization and dropout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff7f63a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.7521 - accuracy: 0.8210 - val_loss: 0.5630 - val_accuracy: 0.8468\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.8486 - val_loss: 0.5569 - val_accuracy: 0.8321\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4884 - accuracy: 0.8558 - val_loss: 0.5168 - val_accuracy: 0.8440\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4682 - accuracy: 0.8615 - val_loss: 0.5115 - val_accuracy: 0.8406\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4567 - accuracy: 0.8648 - val_loss: 0.4931 - val_accuracy: 0.8526\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4439 - accuracy: 0.8673 - val_loss: 0.4742 - val_accuracy: 0.8546\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4322 - accuracy: 0.8712 - val_loss: 0.4518 - val_accuracy: 0.8634\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4248 - accuracy: 0.8718 - val_loss: 0.4524 - val_accuracy: 0.8647\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 0.4154 - accuracy: 0.8767 - val_loss: 0.4608 - val_accuracy: 0.8631\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4085 - accuracy: 0.8774 - val_loss: 0.4629 - val_accuracy: 0.8602\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4045 - accuracy: 0.8781 - val_loss: 0.4531 - val_accuracy: 0.8623\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3981 - accuracy: 0.8801 - val_loss: 0.4400 - val_accuracy: 0.8674\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3950 - accuracy: 0.8806 - val_loss: 0.4442 - val_accuracy: 0.8634\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3938 - accuracy: 0.8812 - val_loss: 0.4436 - val_accuracy: 0.8638\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3881 - accuracy: 0.8822 - val_loss: 0.4380 - val_accuracy: 0.8689\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3883 - accuracy: 0.8832 - val_loss: 0.4392 - val_accuracy: 0.8641\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 0.3840 - accuracy: 0.8838 - val_loss: 0.4326 - val_accuracy: 0.8664\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3816 - accuracy: 0.8843 - val_loss: 0.4670 - val_accuracy: 0.8546\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3790 - accuracy: 0.8844 - val_loss: 0.4230 - val_accuracy: 0.8689\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3771 - accuracy: 0.8854 - val_loss: 0.4503 - val_accuracy: 0.8585\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Reshape the data\n",
    "x_train = x_train.reshape((60000, 28 * 28))\n",
    "x_test = x_test.reshape((10000, 28 * 28))\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Create a model with L2 regularization\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile and train the model\n",
    "network.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_regularized = network.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5380ebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5592 - accuracy: 0.8007 - val_loss: 0.4341 - val_accuracy: 0.8435\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4254 - accuracy: 0.8439 - val_loss: 0.3991 - val_accuracy: 0.8578\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3940 - accuracy: 0.8561 - val_loss: 0.3857 - val_accuracy: 0.8577\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3753 - accuracy: 0.8618 - val_loss: 0.3666 - val_accuracy: 0.8668\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3590 - accuracy: 0.8681 - val_loss: 0.3699 - val_accuracy: 0.8633\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3486 - accuracy: 0.8728 - val_loss: 0.3583 - val_accuracy: 0.8701\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 0.3390 - accuracy: 0.8750 - val_loss: 0.3611 - val_accuracy: 0.8718\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.8782 - val_loss: 0.3519 - val_accuracy: 0.8736\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3216 - accuracy: 0.8822 - val_loss: 0.3307 - val_accuracy: 0.8805\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3174 - accuracy: 0.8824 - val_loss: 0.3362 - val_accuracy: 0.8787\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3133 - accuracy: 0.8831 - val_loss: 0.3387 - val_accuracy: 0.8767\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3080 - accuracy: 0.8856 - val_loss: 0.3248 - val_accuracy: 0.8828\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3013 - accuracy: 0.8880 - val_loss: 0.3378 - val_accuracy: 0.8800\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2974 - accuracy: 0.8893 - val_loss: 0.3374 - val_accuracy: 0.8776\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 0.2938 - accuracy: 0.8893 - val_loss: 0.3287 - val_accuracy: 0.8844\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2875 - accuracy: 0.8924 - val_loss: 0.3253 - val_accuracy: 0.8878\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2838 - accuracy: 0.8935 - val_loss: 0.3312 - val_accuracy: 0.8821\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2841 - accuracy: 0.8935 - val_loss: 0.3216 - val_accuracy: 0.8860\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2759 - accuracy: 0.8978 - val_loss: 0.3310 - val_accuracy: 0.8864\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2738 - accuracy: 0.8974 - val_loss: 0.3212 - val_accuracy: 0.8878\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Reshape the data\n",
    "x_train = x_train.reshape((60000, 28 * 28))\n",
    "x_test = x_test.reshape((10000, 28 * 28))\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Create a model with dropout\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dropout(0.5))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile and train the model\n",
    "network.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_dropout = network.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce08f3b",
   "metadata": {},
   "source": [
    "Observations and Justification:\n",
    "\n",
    "Regularization:\n",
    "The impact of regularization can be observed by comparing the accuracy and overfitting in the regularized model (history_regularized) with the unregularized model. Regularization should help prevent overfitting.\n",
    "You can tune the regularization factor (0.001 in this case) to see how it affects the trade-off between training and test accuracy. A higher value would introduce stronger regularization.\n",
    "Regularization typically helps improve generalization, reducing overfitting in the test dataset. You should see a smaller gap between training and test accuracy in the regularized model.\n",
    "\n",
    "Dropout:\n",
    "The impact of dropout can be observed by comparing the accuracy and overfitting in the dropout model (history_dropout) with the model without dropout. Dropout should also help prevent overfitting.\n",
    "The dropout rate (0.5 in this case) can be adjusted to control the fraction of neurons dropped during training. A higher rate introduces more dropout.\n",
    "Dropout can help improve test accuracy by reducing overfitting. You should observe that the model with dropout has a smaller gap between training and test accuracy compared to the model without dropout.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In both cases, the goal is to reduce overfitting, and the choice of regularization factor or dropout rate depends on the specific dataset and model complexity. By using these techniques, you should achieve more robust models that generalize better to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6721323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a43d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
